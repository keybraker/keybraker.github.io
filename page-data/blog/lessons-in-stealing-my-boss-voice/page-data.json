{"componentChunkName":"component---src-templates-post-js","path":"/blog/lessons-in-stealing-my-boss-voice/","result":{"data":{"mdx":{"slug":"lessons-in-stealing-my-boss-voice/","frontmatter":{"title":"Lessons in Stealing My Boss' Voice","date":"2018-03-01","excerpt":null},"body":"function _extends() { _extends = Object.assign || function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { if (Object.prototype.hasOwnProperty.call(source, key)) { target[key] = source[key]; } } } return target; }; return _extends.apply(this, arguments); }\n\nfunction _objectWithoutProperties(source, excluded) { if (source == null) return {}; var target = _objectWithoutPropertiesLoose(source, excluded); var key, i; if (Object.getOwnPropertySymbols) { var sourceSymbolKeys = Object.getOwnPropertySymbols(source); for (i = 0; i < sourceSymbolKeys.length; i++) { key = sourceSymbolKeys[i]; if (excluded.indexOf(key) >= 0) continue; if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue; target[key] = source[key]; } } return target; }\n\nfunction _objectWithoutPropertiesLoose(source, excluded) { if (source == null) return {}; var target = {}; var sourceKeys = Object.keys(source); var key, i; for (i = 0; i < sourceKeys.length; i++) { key = sourceKeys[i]; if (excluded.indexOf(key) >= 0) continue; target[key] = source[key]; } return target; }\n\n/* @jsxRuntime classic */\n\n/* @jsx mdx */\nvar _frontmatter = {\n  \"title\": \"Lessons in Stealing My Boss' Voice\",\n  \"date\": \"2018-03-01\",\n  \"publish\": true\n};\nvar layoutProps = {\n  _frontmatter: _frontmatter\n};\nvar MDXLayout = \"wrapper\";\nreturn function MDXContent(_ref) {\n  var components = _ref.components,\n      props = _objectWithoutProperties(_ref, [\"components\"]);\n\n  return mdx(MDXLayout, _extends({}, layoutProps, props, {\n    components: components,\n    mdxType: \"MDXLayout\"\n  }), mdx(\"section\", {\n    className: \"blog-section\"\n  }, mdx(\"p\", null, \"The first time I heard audio generated with \", mdx(\"a\", {\n    href: \"https://lyrebird.ai/\"\n  }, \"Lyrebird\"), \" I was in my car on the way home from \", mdx(\"a\", {\n    href: \"https://www.barkleyus.com/\"\n  }, \"Barkley\"), \", listening to NPR. I remember this distinctly. \", mdx(\"a\", {\n    href: \"https://www.npr.org/2017/05/05/527013820/new-software-can-mimic-anyones-voice\"\n  }, \"The story\"), \" was about a Canadian start-up using machine learning to capture and then mimic anyone\\u2019s voice, synthesizing novel phrases in a spookily convincing simulacrum. It was one of those moments that have been happening more and more recently, where feats previously only featured in sci-fi are brought into actuality. You knew the future would get here \", mdx(\"em\", {\n    parentName: \"p\"\n  }, \"eventually\"), \", but had no idea how soon it\\u2019d actually be.\"), mdx(\"p\", null, \"The story played audio synthesized with Lyrebird models trained on both Barack Obama and Donald Trump. To be clear, I wasn\\u2019t fooled entirely\\u200A\\u2014\\u200Aphrases generated with the system still somewhat tinny and robotic, lacking convincing phrasing and execution. Nevertheless, there\\u2019s no doubt about who the model is imitating. Just like the computer graphics of the 90\\u2019s, Lyrebird\\u2019s synthesis is convincing enough to be a harbinger of a future where it\\u2019s nearly impossible to distinguish the real from the artificial.\"), mdx(\"p\", null, \"This being the case, the technology was a natural shoe-in for Moonshot\\u2019s recently completed exhibit about Conversational Interfaces, which we\\u2019ve named Marco Polo. For more information about the exhibit as a whole, here\\u2019s \", mdx(\"a\", {\n    href: \"https://medium.com/moonshotlab/marco-polo-58201c14c669\"\n  }, \"a quick write-up\"), \" by Barkley\\u2019s SVP of Innovation, \", mdx(\"a\", {\n    href: \"https://www.linkedin.com/in/marklogan/\"\n  }, \"Mark Logan\"), \".\"), mdx(\"iframe\", {\n    width: \"100%\",\n    height: \"166\",\n    scrolling: \"no\",\n    frameBorder: \"no\",\n    src: \"https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/318661840&color=ff5500\"\n  }), mdx(\"p\", null, \"This being the case, the technology was a natural shoe-in for Moonshot\\u2019s recently completed exhibit about Conversational Interfaces, which we\\u2019ve named Marco Polo. For more information about the exhibit as a whole, here\\u2019s a quick write-up by Barkley\\u2019s SVP of Innovation, Mark Logan.\"), mdx(\"div\", {\n    className: \"blog-inset\"\n  }, mdx(ZoomImage, {\n    src: jasmine,\n    zoomSrc: jasmineZoom,\n    alt: \"Lyrebird Demo, In Situ\",\n    caption: \"Lyrebird Demo, In Situ\",\n    mdxType: \"ZoomImage\"\n  }))), mdx(\"section\", {\n    className: \"blog-section\"\n  }, mdx(\"h2\", {\n    \"id\": \"the-surprising-power-of-asking-nicely\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"href\": \"#the-surprising-power-of-asking-nicely\",\n    \"aria-label\": \"the surprising power of asking nicely permalink\",\n    \"className\": \"anchor before\"\n  }), mdx(\"svg\", _extends({\n    parentName: \"a\"\n  }, {\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }), mdx(\"path\", _extends({\n    parentName: \"svg\"\n  }, {\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), \"The Surprising Power of Asking Nicely\"), mdx(\"p\", null, \"After deciding that we wanted to showcase Lyrebird in our exhibit, the next step was to figure out how. Lyrebird has a functional \", mdx(\"a\", {\n    href: \"https://lyrebird.ai/signup\"\n  }, \"demo\"), \" available for anyone to try out: simply record a minimum of 30 pre-selected sentences, and voil\\xE0, you can start synthesizing phrases with your artificial voice. You can keep on recording sentences to improve accuracy\\u200A\\u2014\\u200A30 sentences is okay, 50 sentences sounds pretty good, and 100 sentences sounds even better. We came up with the idea of getting Jeff King, Barkley\\u2019s CEO, to train a model and then giving Barkley partners the opportunity to make their boss say whatever they want. What could go wrong?\"), mdx(\"p\", null, \"The only issue is that we were confined to generating audio on Lyrebird\\u2019s web site, as opposed to a separate experience designed to fit with the rest of the exhibit. Rather than using a text input, we wanted to allow users to speak a phrase, have the audio transcribed before being generated by Lyrebird, then played back to the user.\"), mdx(\"p\", null, \"After a few failed attempts at other solutions, I realized I hadn\\u2019t tried the simplest one: reaching out to Lyrebird and asking for API access. I wrote a quick email to the address on their contact page and a few days later had a response in my inbox asking for a time to have a quick phone call. After making contact, I described how I would be using the technology, and to my surprise, we were granted beta access to their developer API! This would allow us to train a voice model, then make an API call to generate audio on the fly\\u200A\\u2014\\u200Aexactly what we needed.\")), mdx(\"section\", {\n    className: \"blog-section\"\n  }, mdx(\"h2\", {\n    \"id\": \"capturing-a-voice\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"href\": \"#capturing-a-voice\",\n    \"aria-label\": \"capturing a voice permalink\",\n    \"className\": \"anchor before\"\n  }), mdx(\"svg\", _extends({\n    parentName: \"a\"\n  }, {\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }), mdx(\"path\", _extends({\n    parentName: \"svg\"\n  }, {\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), \"Capturing A Voice\"), mdx(\"p\", null, \"The next step was to actually train our voice model. We booked some time with Jeff to come in and record with a nice microphone in the production team\\u2019s sound-proof edit bay. Training a model with Lyrebird is incredibly simple but tedious: just press \\u2018record\\u2019, then read aloud a sentence given to you by Lyrebird (e.g. \\u201CThat\\u2019s a sophisticated mechanical system! We want to disperse the core from the hull\\u201D). In about 15 minutes we hit the minimum of 30 sentences, but we kept on recording to try and get the best model we could. After 100 sentences, \\u2018fake Jeff\\u2019 was sounding pretty convincing.\"), mdx(\"div\", {\n    className: \"blog-inset\"\n  }, mdx(ZoomImage, {\n    src: jeff,\n    zoomSrc: jeffZoom,\n    alt: \"Recording Session with Barkley CEO Jeff King\",\n    caption: \"Recording Session with Barkley CEO Jeff King\",\n    mdxType: \"ZoomImage\"\n  }))), mdx(\"section\", {\n    className: \"blog-section\"\n  }, mdx(\"h2\", {\n    \"id\": \"pulling-it-all-together\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"href\": \"#pulling-it-all-together\",\n    \"aria-label\": \"pulling it all together permalink\",\n    \"className\": \"anchor before\"\n  }), mdx(\"svg\", _extends({\n    parentName: \"a\"\n  }, {\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }), mdx(\"path\", _extends({\n    parentName: \"svg\"\n  }, {\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), \"Pulling It All Together\"), mdx(\"p\", null, \"After training our voice model, the last step was to build out the exhibit experience. We liked the idea of having a minimal interface\\u200A\\u2014\\u200Apress a button, say a phrase, then hear the phrase spoken back in Jeff\\u2019s voice. Using Lyrebird\\u2019s API ended up being easy to work with and well documented. We ended up using Google Cloud \", mdx(\"a\", {\n    href: \"https://cloud.google.com/speech/\"\n  }, \"Speech API\"), \" for audio transcription, which was quick and reliable. A bit of Arduino \", mdx(\"a\", {\n    href: \"https://github.com/MoonshotLab/lyrebird-demo/blob/master/arduino/uno/uno.ino\"\n  }, \"code\"), \" allowed a button to interface with the main application\\u2019s Node.js \", mdx(\"a\", {\n    href: \"https://github.com/MoonshotLab/lyrebird-demo/blob/master/lib/arduino.js\"\n  }, \"back end\"), \" via a USB port.\"), mdx(\"p\", null, \"Despite being an exciting and impressive product, Lyrebird still has a way to go. While the 100 sentences we recorded with Jeff were more than enough to generate most longer phrases convincingly, for some reason Lyrebird struggles with shorter phrases and single words.\"), mdx(\"p\", null, \"For example, \\u201CMy name is Jeff\\u201D trails off with a robotic slurring at the end:\"), mdx(\"iframe\", {\n    width: \"100%\",\n    height: \"166\",\n    scrolling: \"no\",\n    frameBorder: \"no\",\n    src: \"https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/402074355&color=ff5500\"\n  }), mdx(\"p\", null, \"Yet longer phrases sound convincing, even with difficult words like \\u2018Orangutan\\u2019 and \\u2018Worcestershire\\u2019 (neither of which appear in the original source recordings):\"), mdx(\"iframe\", {\n    width: \"100%\",\n    height: \"166\",\n    scrolling: \"no\",\n    frameBorder: \"no\",\n    src: \"https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/402074367&color=ff5500\"\n  }), mdx(\"p\", null, \"Cadence and emphasis also leave something to be desired. For example, the model struggles with counting:\"), mdx(\"iframe\", {\n    width: \"100%\",\n    height: \"166\",\n    scrolling: \"no\",\n    frameBorder: \"no\",\n    src: \"https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/402074385&color=ff5500\"\n  }), mdx(\"p\", null, \"There also seems to be a persistent low-volume buzz in all of the recordings. This can certainly be stripped out with post-processing, and I assume it will eventually be removed from the generated audio, but for now it can sometimes be distracting. Here\\u2019s a demonstration of raw compared to post-processed audio:\"), mdx(\"iframe\", {\n    width: \"100%\",\n    height: \"166\",\n    scrolling: \"no\",\n    frameBorder: \"no\",\n    src: \"https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/402689490&color=ff5500\"\n  })), mdx(\"section\", {\n    className: \"blog-section\"\n  }, mdx(\"h2\", {\n    \"id\": \"moving-forward\",\n    \"style\": {\n      \"position\": \"relative\"\n    }\n  }, mdx(\"a\", _extends({\n    parentName: \"h2\"\n  }, {\n    \"href\": \"#moving-forward\",\n    \"aria-label\": \"moving forward permalink\",\n    \"className\": \"anchor before\"\n  }), mdx(\"svg\", _extends({\n    parentName: \"a\"\n  }, {\n    \"aria-hidden\": \"true\",\n    \"focusable\": \"false\",\n    \"height\": \"16\",\n    \"version\": \"1.1\",\n    \"viewBox\": \"0 0 16 16\",\n    \"width\": \"16\"\n  }), mdx(\"path\", _extends({\n    parentName: \"svg\"\n  }, {\n    \"fillRule\": \"evenodd\",\n    \"d\": \"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"\n  })))), \"Moving Forward\"), mdx(\"p\", null, \"Audio synthesis technology like Lyrebird is on the cusp of being convincing enough to be scary. It\\u2019s not quite there just yet, but in the next few years we collectively will have to confront the fact that any audio may very well be falsified.\"), mdx(\"p\", null, \"On the one hand, it will change the practice of advertising and video / audio production forever. Imagine if you no longer need to hire voiceover artists and can simply design the perfect artificial voice with which to synthesize voiceover or narration. Such advancements will be a boon for creative agencies and anyone involved in video production, but may put some voice actors out of business. Technologies like Lyrebird could also allow us to record our voices for posterity, allowing future generations to converse with their departed ancestors.\"), mdx(\"p\", null, \"On the other hand, there are obvious and vital implications for the way that we understand and judge news reporting. With accusations of fake news at an all-time high, it will only become more difficult to distinguish the actual from the synthesized. Furthermore, parallel advancements in video synthesis will be married with audio synthesis technology to create convincingly faked video content. These techniques are already being used to do everything from \", mdx(\"a\", {\n    href: \"https://mashable.com/2018/01/31/nicolas-cage-face-swapping-deepfakes/\"\n  }, \"face-swapping Nicholas Cage\"), \" into random movies to creating \", mdx(\"a\", {\n    href: \"https://www.theverge.com/2018/1/24/16929148/fake-celebrity-porn-ai-deepfake-face-swapping-artificial-intelligence-reddit\"\n  }, \"fake celebrity porn\"), \" (sfw).\"), mdx(\"p\", null, \"While developers of these powerful technologies are responsible for taking all reasonable steps to make sure that their products are used ethically and legally, ultimately the onus falls on us to reinvestigate as a society how we decide what is real and what is fake. Just as the advent of Photoshop didn\\u2019t irreversibly corrupt photojournalism, I believe we will establish reliable techniques to make sense of the media we consume. We simply must remember not to blindly believe our eyes (or in this case, our ears).\"), mdx(\"iframe\", {\n    width: \"100%\",\n    height: \"166\",\n    scrolling: \"no\",\n    frameBorder: \"no\",\n    src: \"https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/402706653&color=ff5500\"\n  }), mdx(\"blockquote\", null, mdx(\"p\", {\n    parentName: \"blockquote\"\n  }, \"This post originally appeared on Moonshot\\u2019s \", mdx(\"a\", {\n    href: \"https://medium.com/moonshotlab/lessons-in-stealing-my-bosses-voice-a56fb290f330\"\n  }, \"Medium\"), \".\"))));\n}\n;\nMDXContent.isMDXComponent = true;"}},"pageContext":{"slug":"/blog/lessons-in-stealing-my-boss-voice/"}},"staticQueryHashes":[]}